# backend/agent/__init__.py  â–¶ ìˆ˜ì •ë³¸ ì „ë¶€

from __future__ import annotations
import os, json, datetime as dt
from typing import List, Dict, Any, Literal
from zoneinfo import ZoneInfo

from sqlalchemy.orm import Session
from openai import OpenAI, AsyncOpenAI
import httpx

from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain.schema import SystemMessage
from langchain_core.tools import BaseTool
from langchain_core.tools import tool  # â¬…ï¸ ë°ì½”ë ˆì´í„°
from pydantic import BaseModel, Field

import models
from routers.gcal import build_gcal_service
from routers.search import google_search_cse
from utils.image import fetch_and_resize

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OpenAI í´ë¼ì´ì–¸íŠ¸
_sync_root = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    http_client=httpx.Client(
        timeout=30.0,
        limits=httpx.Limits(max_keepalive_connections=20),
    ),
)
_async_root = AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    http_client=httpx.AsyncClient(
        timeout=30.0,
        limits=httpx.Limits(max_keepalive_connections=20),
    ),
)


class _SyncChat:
    def create(self, **kwargs):
        return _sync_root.chat.completions.create(**kwargs)


class _AsyncChat:
    async def create(self, **kwargs):
        return await _async_root.chat.completions.create(**kwargs)


_llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.2,
    client=_SyncChat(),
    async_client=_AsyncChat(),
)

# â”€â”€ pydantic ìŠ¤í‚¤ë§ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class CreateEventArgs(BaseModel):
    title: str  = Field(..., description="ì¼ì • ì œëª©")
    start: str  = Field(..., description="ISO-8601 ì‹œì‘")
    end:   str  = Field(..., description="ISO-8601 ì¢…ë£Œ")

class DeleteEventArgs(BaseModel):
    event_id: str

class WebSearchArgs(BaseModel):
    query: str
    k: int = 5

class GenImgArgs(BaseModel):
    prompt: str = Field(..., description="DALL-E í”„ë¡¬í”„íŠ¸")

class RecArgs(BaseModel):
    types: str
    limit: int = 5
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tool ì„¸íŠ¸
def _make_toolset(db: Session, user: models.User, tz: ZoneInfo):

    @tool(args_schema=CreateEventArgs, return_direct=True)
    def create_event(title: str, start: str, end: str) -> str:
        """Google Calendar ì¼ì • ìƒì„±. ì‚¬ìš©ìê°€ ì¼ì •, ë¯¸íŒ…, ì•½ì† ë“±ì„ ì¡ì•„ë‹¬ë¼ê³  í•  ë•Œ í•­ìƒ ì‚¬ìš©í•˜ì„¸ìš”.
        
        title: ì¼ì • ì œëª© (ì˜ˆ: "íŒ€ íšŒì˜", "ì ì‹¬ ì•½ì†")
        start: ISO-8601 ì‹œì‘ ì‹œê°„ (ì˜ˆ: "2025-05-26T13:00:00+02:00")
        end: ISO-8601 ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: "2025-05-26T14:00:00+02:00")
        
        ì¼ì • ìƒì„±ì€ í•­ìƒ ë¯¸ë˜ ì‹œê°„ì—ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """
        print("---------------------------------------")
        print("create_event í˜¸ì¶œë¨!")
        print(f"ë§¤ê°œë³€ìˆ˜: title={title}, start={start}, end={end}")
        print("---------------------------------------")
        try:
            # 1) ISO â†’ datetime
            try:
                dt_start = dt.datetime.fromisoformat(start)
                dt_end = dt.datetime.fromisoformat(end)
            except ValueError as e:
                print(f"ISO íŒŒì‹± ì‹¤íŒ¨: {start}, {end}, ì˜¤ë¥˜: {e}")
                return f"â— ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}"

            # 2) íƒ€ì„ì¡´ ì²˜ë¦¬
            if dt_start.tzinfo is None:
                dt_start = dt_start.replace(tzinfo=tz)
            if dt_end.tzinfo is None:
                dt_end = dt_end.replace(tzinfo=tz)
            
            # 3) í˜„ì¬ ì‹œê°„
            now = dt.datetime.now(tz)
            print(f"ì‹œê°„ ë¹„êµ: ì‹œì‘={dt_start}, í˜„ì¬={now}")
            
            # 4) ë¯¸ë˜ ì¼ì • í™•ì¸ (10ë¶„ ì´ë‚´ëŠ” í—ˆìš©)
            if dt_start < now - dt.timedelta(minutes=10):
                return f"â— ê³¼ê±° ì‹œê°„({dt_start.strftime('%Y-%m-%d %H:%M')})ì—ëŠ” ì¼ì •ì„ ì¶”ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì‹œê°„ì€ {now.strftime('%Y-%m-%d %H:%M')}ì…ë‹ˆë‹¤."
            
            # 5) Google Calendar API í˜¸ì¶œ
            svc = build_gcal_service(db, user.id)
            print(f"ì¼ì • ìƒì„± ì‹œë„: {title}, {dt_start} ~ {dt_end}")
            ev = svc.events().insert(
                calendarId="primary",
                body={
                    "summary": title,
                    "start": {"dateTime": dt_start.isoformat(), "timeZone": str(tz)},
                    "end": {"dateTime": dt_end.isoformat(), "timeZone": str(tz)},
                },
            ).execute()

            result = f"âœ… ì¼ì • ìƒì„± ì™„ë£Œ â†’ {dt_start.strftime('%Y-%m-%d %H:%M')} ~ {dt_end.strftime('%H:%M')} {ev.get('htmlLink')}"
            print(result)
            return result
        except Exception as e:
            print(f"ì¼ì • ìƒì„± ì˜¤ë¥˜: {e}")
            return f"â— ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    @tool(args_schema=DeleteEventArgs, return_direct=True)
    def delete_event(event_id: str) -> str:
        """event_id ë¡œ Google Calendar ì´ë²¤íŠ¸ë¥¼ ì‚­ì œí•œë‹¤."""
        svc = build_gcal_service(db, user.id)
        svc.events().delete(calendarId="primary", eventId=event_id).execute()
        return "ğŸ—‘ï¸ ì¼ì •ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."

    @tool(args_schema=WebSearchArgs)
    def web_search(query: str, k: int = 5) -> str:
        """Google CSE ë¡œ ì›¹ì„ ê²€ìƒ‰í•˜ê³  ìƒìœ„ kê°œ ë§í¬ë¥¼ ëŒë ¤ì¤€ë‹¤."""
        items = google_search_cse(query=query, num=k, date_restrict="m6", sort="date")
        return "\n".join(f"{it['title']} â€“ {it['link']}" for it in items) or "No results"

    @tool(args_schema=GenImgArgs, return_direct=True)
    def generate_image(prompt: str) -> str:
        """DALL-E 3 ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ base64 JSON ì„ ëŒë ¤ì¤€ë‹¤."""
        try:
            resp = _sync_root.images.generate(
                model="dall-e-3", prompt=prompt, n=1, size="1024x1024"
            )
            url = resp.data[0].url
            orig, thumb = fetch_and_resize(url)
            payload = {
                "prompt": prompt,
                "original_b64": orig,
                "thumb_b64": thumb,
            }
            return json.dumps(payload, ensure_ascii=False)   # â˜… ë°˜ë“œì‹œ str!
        except Exception as e:
            return json.dumps({"error": f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}"}, ensure_ascii=False)

    @tool(args_schema=RecArgs, return_direct=True)
    def fetch_recommendations(types: str, limit: int = 5) -> str:
        """
        ONLY USE THIS TOOL when the user EXPLICITLY asks for content recommendations or suggestions.
        
        APPROPRIATE USES:
        - User asks "ë­ ë³¼ê¹Œ?" (What should I watch?)
        - User says "ì˜í™” ì¶”ì²œí•´ì¤˜" (Recommend me a movie)
        - User asks for options or suggestions for content to consume
        
        DO NOT USE FOR:
        - Technical questions like "Reactë€ ë¬´ì—‡ì¸ê°€?"
        - Factual information queries like "TypeScriptì˜ ì¥ì ì€?"
        - General knowledge or explanations
        
        This tool returns personalized content recommendation cards as JSON.
        """
        from routers.recommend import get_recommendations
        recs = get_recommendations(
            types=types, limit=limit, db=db, current_user=user, tz=tz, user_query=""
        )
        return json.dumps({"cards": recs}, ensure_ascii=False)

    return [
        create_event,
        delete_event,
        web_search,
        generate_image,
        fetch_recommendations,
    ]

def tz_label(tz: dt.tzinfo) -> str:
    return getattr(tz, "key", None) or tz.tzname(None) or "UTC"

def _make_time_system_prompt(client_tz: ZoneInfo) -> str:
    now_local     = dt.datetime.now(client_tz)
    now_client    = now_local.isoformat(timespec="seconds")
    today_str     = now_local.date().isoformat()
    tomorrow_str  = (now_local.date() + dt.timedelta(days=1)).isoformat()

    # ì˜ˆì œ ì‹œê°„ (ë¯¸ë¦¬ ê³„ì‚°)
    afternoon_example = (now_local.replace(hour=13, minute=0, second=0) + 
                     dt.timedelta(days=(0 if now_local.hour < 13 else 1))).isoformat()

    system_prompt = (
        "You are an AI assistant that can also manage the user's Google Calendar.\n"
        f"â±ï¸ **Current client time ({tz_label(client_tz)}):** {now_client}\n\n"
        
        "## CALENDAR INSTRUCTIONS\n"
        f"- Today's date is {today_str} in timezone {tz_label(client_tz)}\n"
        f"- Tomorrow's date is {tomorrow_str}\n"
        f"- Current hour is {now_local.hour}\n"
        "- When user mentions 'ì˜¤ëŠ˜' (today), use today's date\n"
        "- When user mentions 'ë‚´ì¼' (tomorrow), use tomorrow's date\n"
        "- 'ì˜¤ì „' means AM, 'ì˜¤í›„' means PM\n"
        f"- Example: 'ì˜¤ëŠ˜ ì˜¤í›„ 1ì‹œ' should be interpreted as {afternoon_example}\n"
        "- ALWAYS create events in the FUTURE (after current time)\n"
        "- ALWAYS use the create_event tool for calendar requests\n\n"
        
        "## TOOL USAGE GUIDELINES\n"
        "- Use calendar tools (create_event, delete_event) when the user wants to manage their schedule\n"
        "- Use web_search when the user asks for current information or news\n"
        "- Use generate_image when the user asks to create or visualize an image\n\n"
        
        "## ABOUT THE RECOMMENDATION TOOL\n"
        "The fetch_recommendations tool should ONLY be used when:\n"
        "1. The user is EXPLICITLY asking for content suggestions, recommendations, or options\n"
        "2. The user is asking what to watch, read, or consume\n"
        "3. The user uses phrases like 'ì¶”ì²œí•´ì¤˜', 'ë­ ë³¼ê¹Œ?', 'ì–´ë–¤ ê²Œ ì¢‹ì„ê¹Œ?'\n\n"
        
        "NEVER use fetch_recommendations for:\n"
        "1. Technical explanations (e.g., 'Reactë€ ë¬´ì—‡ì¸ê°€?', 'TypeScriptì˜ ì¥ì ')\n"
        "2. Factual questions (e.g., 'íŒŒì´ì¬ í•¨ìˆ˜ ì •ì˜ ë°©ë²•', 'í•œêµ­ì˜ ìˆ˜ë„ëŠ”?')\n"
        "3. General conversation or advice\n\n"
        
        "If no tool is appropriate, just respond with a direct text answer. Most queries should be answered with text, not tools.\n"
    )
    print(system_prompt)
    return system_prompt

def format_tool_to_str(tool) -> str:
    """
    LangChain <0.3 ê³„ì—´ì— render util ì´ ì—†ì„ ë•Œ ì“°ëŠ” í´ë¦¬-í•„.
    LLM ì´ ì‰½ê²Œ ë”°ë¼ í•  ìˆ˜ ìˆë„ë¡ **JSON ì˜ˆì‹œ** ê¹Œì§€ ë„£ì–´ ì¤€ë‹¤.
    """
    fields = getattr(tool, "args_schema", None)
    fields   = getattr(tool, "args_schema", None)
    sample_args: dict[str, str] = {}
    if fields:
        for name, field in fields.__fields__.items():
            # pydantic v1 â†’ ModelField  /  v2 â†’ FieldInfo
            tp = (
                getattr(field, "annotation", None)   # v2
                or getattr(field, "outer_type_", None)  # v1
                or str
            )
            type_name = getattr(tp, "__name__", str(tp))
            sample_args[name] = f"<{type_name}>"
    return f"{tool.name} â€“ {tool.description or ''}"

def build_prompt(tools: list[BaseTool], tz: ZoneInfo) -> ChatPromptTemplate:
    tool_block  = "\n".join(format_tool_to_str(t) for t in tools)
    system_str  = _make_time_system_prompt(tz)

    # ì™„ì „íˆ í•˜ë“œì½”ë”©ëœ ì˜ˆì œ (ë¬¸ìì—´ í…œí”Œë¦¿ ë³€ìˆ˜ ì—†ìŒ)
    examples = """
    EXAMPLES:
    
    User: "TypeScriptë€ ë¬´ì—‡ì¸ê°€ìš”?"
    Assistant: TypeScriptëŠ” Microsoftì—ì„œ ê°œë°œí•œ JavaScriptì˜ ìƒìœ„ì§‘í•©(superset) í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤...
    
    User: "ì˜¤ëŠ˜ ì˜¤í›„ 1ì‹œì— íŒ€ íšŒì˜ ì¡ì•„ì¤˜"
    Assistant: {{"name": "create_event", "arguments": {{"title": "íŒ€ íšŒì˜", "start": "2025-05-26T13:00:00+02:00", "end": "2025-05-26T14:00:00+02:00"}}}}
    
    User: "ë‚´ì¼ ì ì‹¬ ì•½ì† ì¼ì • ì¶”ê°€í•´ì¤˜"
    Assistant: {{"name": "create_event", "arguments": {{"title": "ì ì‹¬ ì•½ì†", "start": "2025-05-27T12:00:00+02:00", "end": "2025-05-27T13:00:00+02:00"}}}}
    
    User: "ì˜í™” ì¶”ì²œí•´ì¤˜"
    Assistant: {{"name": "fetch_recommendations", "arguments": {{"types": "movie", "limit": 5}}}}
    
    User: "Reactì˜ ì¥ì ì´ ë­ì•¼?"
    Assistant: Reactì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: 1) ê°€ìƒ DOMì„ í†µí•œ íš¨ìœ¨ì ì¸ ë Œë”ë§...
    """

    system_message = ("system",
             f"{system_str}\n\n"
             "You have access to the following tools:\n"
             f"{tool_block}\n"
             #f"{examples}\n\n"
             "When handling calendar requests:\n"
             "1. ALWAYS convert relative times to absolute ISO datetime\n"
             "2. ALWAYS check that the time is in the future\n"
             "3. ALWAYS include timezone information\n"
             "4. NEVER respond with natural language for calendar requests - use the tool\n\n"
             "When you need a tool, reply **only** with the JSON shown in the example -- "
             "no markdown, no extra keys, no natural-language."
            )
    print(system_message)

    return ChatPromptTemplate.from_messages(
        [
            system_message,
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
            ("assistant", "{agent_scratchpad}"),
        ]
    )

def _clean_history(messages: list[models.Message]) -> list[tuple[str,str]]:
    """ê¸°ëŠ¥-ì‘ë‹µ(âœ…/ğŸ—‘ï¸/â—/JSON) ì œê±° í›„ (role,text) íŠœí”Œ ë°˜í™˜"""
    cleaned = []
    for m in messages[-15:]:
        if m.role == "assistant":
            t = m.content.strip()
            if t.startswith(("âœ…", "ğŸ—‘ï¸", "â—", "ğŸ“·", '{"card_id', '{"prompt')):
                continue
        cleaned.append((m.role, m.content))
    return cleaned

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì—ì´ì „íŠ¸
def build_agent(
    db: Session,
    user: models.User,
    tz: ZoneInfo = ZoneInfo("UTC"),
    history: list[models.Message] | None = None,
) -> AgentExecutor:
    # 1) memory (ìµœê·¼ 15ê°œ, ì´ë¯¸ì§€/ì¹´ë“œ/í™•ì¸ë©”ì‹œì§€ ì œê±°)
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        input_key="input",
        return_messages=True,
    )
    for role, text in _clean_history(history or []):
        (memory.chat_memory.add_user_message if role == "user"
         else memory.chat_memory.add_ai_message)(text)

    # 2) tools & prompt
    tools  = _make_toolset(db, user, tz)
    prompt = build_prompt(tools, tz)

    # 3) agent â†’ executor
    agent   = create_openai_tools_agent(_llm, tools, prompt)   # âœ… system_message ì•ˆ ë„˜ê¹€
    exec_   = AgentExecutor(
        agent   = agent,
        tools   = tools,
        memory  = memory,
        verbose = True,  # ë””ë²„ê¹…ì„ ìœ„í•´ verbose ëª¨ë“œ í™œì„±í™”
        max_iterations      = 4,
        handle_parsing_errors = True,   # LLM ì´ JSON ê¹¨ëœ¨ë ¤ë„ í•œ ë²ˆ ë” ì‹œë„
        early_stopping_method = "force",  # ë” í™•ì‹¤í•œ ì œì–´
    )
    return exec_
